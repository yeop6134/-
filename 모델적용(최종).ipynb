{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeop6134/Ai_humanities/blob/main/%EB%AA%A8%EB%8D%B8%EC%A0%81%EC%9A%A9(%EC%B5%9C%EC%A2%85).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQR3QnD2Tzuu",
        "outputId": "9f13cc63-49c8-44a4-80b6-f97c09e590f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIx8IAzMYXTJ",
        "outputId": "cb168f87-de29-4d6b-f2cb-5d8cb3163185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from transformers import TFBertForSequenceClassification\n",
        "from transformers import BertTokenizerFast"
      ],
      "metadata": {
        "id": "iLZAlyK7Wj9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 함수로 만들기\n",
        "def ModelTest(model_path, tokenizer_path, test_data_path):\n",
        "  import pandas as pd\n",
        "  import tensorflow as tf\n",
        "  from tensorflow import keras\n",
        "  from transformers import TFBertForSequenceClassification\n",
        "  from transformers import BertTokenizerFast\n",
        "\n",
        "  model = TFBertForSequenceClassification.from_pretrained(model_path)\n",
        "  tokenizer = BertTokenizerFast.from_pretrained(tokenizer_path)\n",
        "\n",
        "  test_data = pd.read_csv(test_data_path, index_col = 0)\n",
        "  print('테스트 데이터 개수 :',len(test_data))\n",
        "\n",
        "  X_test_list = test_data['text'].tolist()\n",
        "  y_test = test_data['label'].tolist()\n",
        "\n",
        "  X_test = tokenizer(X_test_list, truncation=True, padding=True)\n",
        "\n",
        "  val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "      dict(X_test),\n",
        "      y_test\n",
        "  ))\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss=model.hf_compute_loss, metrics=['accuracy'])\n",
        "\n",
        "  model.evaluate(val_dataset.batch(1024))"
      ],
      "metadata": {
        "id": "bmG_rkSMQsGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch'\n",
        "tokenizer_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/tokenizer_BerTokenizerFast_10epoch'\n",
        "test_data_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/데이터전처리/스마게데이터/랜덤추출/여성.csv'\n",
        "\n",
        "ModelTest(model_path, tokenizer_path, test_data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElK07_mY-vzR",
        "outputId": "29f053fc-12e4-4c82-fbbb-f0c5632e0426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 개수 : 20\n",
            "1/1 [==============================] - 11s 11s/step - loss: 1.3633 - accuracy: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch'\n",
        "tokenizer_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/tokenizer_BerTokenizerFast_10epoch'\n",
        "test_data_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/데이터전처리/스마게데이터/랜덤추출/성소수자20개문장.csv'\n",
        "\n",
        "ModelTest(model_path, tokenizer_path, test_data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H5Fdw2XUWNx",
        "outputId": "73065a57-8703-4dad-faab-9a7377d85b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 개수 : 20\n",
            "1/1 [==============================] - 8s 8s/step - loss: 3.9425 - accuracy: 0.4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch'\n",
        "tokenizer_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/tokenizer_BerTokenizerFast_10epoch'\n",
        "test_data_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/데이터전처리/스마게데이터/랜덤추출/연령20개문장.csv'\n",
        "\n",
        "ModelTest(model_path, tokenizer_path, test_data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7jR_AYpUmeC",
        "outputId": "dea03959-3ed9-4cf5-9aa1-e90a315bdfab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 개수 : 20\n",
            "1/1 [==============================] - 7s 7s/step - loss: 2.1283 - accuracy: 0.4500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch'\n",
        "tokenizer_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/tokenizer_BerTokenizerFast_10epoch'\n",
        "test_data_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/데이터전처리/스마게데이터/랜덤추출/인종및국적20개문장.csv'\n",
        "\n",
        "ModelTest(model_path, tokenizer_path, test_data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbMXn9MtUmbC",
        "outputId": "23a5e96b-27b7-4748-a3a1-eb062779b336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 개수 : 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7576cf5ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step - loss: 0.6343 - accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch'\n",
        "tokenizer_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/tokenizer_BerTokenizerFast_10epoch'\n",
        "test_data_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/데이터전처리/스마게데이터/랜덤추출/종교20개문장.csv'\n",
        "\n",
        "ModelTest(model_path, tokenizer_path, test_data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU5Cn-raU0Wk",
        "outputId": "b2f71a70-4fe7-4ffe-d381-00f309ff96dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 개수 : 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f74f50b0af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 10s 10s/step - loss: 3.4164 - accuracy: 0.4500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch'\n",
        "tokenizer_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/tokenizer_BerTokenizerFast_10epoch'\n",
        "test_data_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/데이터전처리/스마게데이터/랜덤추출/지역20개문장.csv'\n",
        "\n",
        "ModelTest(model_path, tokenizer_path, test_data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_QFgKX9U0UL",
        "outputId": "94a6531b-cbc3-45e8-9c6c-39470529a21e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 개수 : 20\n",
            "1/1 [==============================] - 5s 5s/step - loss: 2.4698 - accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch'\n",
        "tokenizer_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/tokenizer_BerTokenizerFast_10epoch'\n",
        "test_data_path = '/content/drive/MyDrive/Colab Notebooks/인공지능인문학/데이터전처리/스마게데이터/랜덤추출/남성20개문장.csv'\n",
        "\n",
        "ModelTest(model_path, tokenizer_path, test_data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIzo1rKIURxA",
        "outputId": "08f3090b-942f-438e-cfe0-0ce5866c6c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/인공지능인문학/BERT기반분류모델/model/독립데이터/json_1레이블수동일/split데이터/model_BerTokenizerFast_10epoch.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 개수 : 20\n",
            "1/1 [==============================] - 9s 9s/step - loss: 2.8017 - accuracy: 0.5500\n"
          ]
        }
      ]
    }
  ]
}